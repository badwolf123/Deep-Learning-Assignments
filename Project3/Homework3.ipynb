{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function                  # Allows for python3 printing\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, Dropout, SimpleRNN,GRU,LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"sonnet.txt\"\n",
    "#read the file and make all chracaters lowercase\n",
    "text = open(filename).read().lower() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text length: 95690\n",
      "total chars: 38\n",
      "['\\n', ' ', '!', \"'\", '(', ')', ',', '-', '.', ':', ';', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "# summarize the loaded data\n",
    "print('text length:', len(text))    # this prints the length of the text \n",
    "\n",
    "chars = sorted(list(set(text)))    # sorted():Return a new list containing all items from the iterable in ascending order.\n",
    "print('total chars:', len(chars))\n",
    "print(chars)\n",
    "##This should print 38."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 encoding and decoding dictionaries\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 cut corpus into equal length sequences\n",
    "maxlen = 40\n",
    "step = 3\n",
    "\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])               \n",
    "    next_chars.append(text[i + maxlen])\n",
    "\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)   #generate zeros with size[number of sentences,40,38]\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool) #generate zeros with size[number of sentences,38]\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 备注\n",
    "这里我尝试了LSTM和GRU，发现使用GRU明显能得到更低的loss。之后我尝试着换用了另外的几个optimizer，其中Nadam使loss较之前有了极大的改善，其输出结果如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(GRU(128, input_shape=(x.shape[1], x.shape[2])))        #using GRU instead of RNN\n",
    "model.add(Dense(len(chars), activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizers.Nadam())   #changed the optimizer to Nadam "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "31884/31884 [==============================] - 23s 725us/step - loss: 2.6146\n",
      "Epoch 2/10\n",
      "31884/31884 [==============================] - 28s 884us/step - loss: 2.1704\n",
      "Epoch 3/10\n",
      "31884/31884 [==============================] - 29s 902us/step - loss: 2.0123\n",
      "Epoch 4/10\n",
      "31884/31884 [==============================] - 30s 943us/step - loss: 1.9044\n",
      "Epoch 5/10\n",
      "31884/31884 [==============================] - 32s 1ms/step - loss: 1.8216\n",
      "Epoch 6/10\n",
      "31884/31884 [==============================] - 35s 1ms/step - loss: 1.7533\n",
      "Epoch 7/10\n",
      "31884/31884 [==============================] - 38s 1ms/step - loss: 1.6925\n",
      "Epoch 8/10\n",
      "31884/31884 [==============================] - 39s 1ms/step - loss: 1.6383\n",
      "Epoch 9/10\n",
      "31884/31884 [==============================] - 39s 1ms/step - loss: 1.5838\n",
      "Epoch 10/10\n",
      "31884/31884 [==============================] - 40s 1ms/step - loss: 1.5327\n",
      "\n",
      "Iteration 1\n",
      " but in my must be thee,\n",
      "when in the will he on the will me all my be,\n",
      "  and the will he on the will my be the with mine\n",
      "of the will my be the will my be the with mine\n",
      "of the will my be the will my be the with mine\n",
      "of the will my be the will my be the with mine\n",
      "of the will my be the will my be the with mine\n",
      "of the will my be the will my be the with mine\n",
      "of the will my be the will my be the with mi\n",
      "\n",
      "Epoch 1/10\n",
      "31884/31884 [==============================] - 44s 1ms/step - loss: 1.4818\n",
      "Epoch 2/10\n",
      "31884/31884 [==============================] - 45s 1ms/step - loss: 1.4299\n",
      "Epoch 3/10\n",
      "31884/31884 [==============================] - 40s 1ms/step - loss: 1.3809\n",
      "Epoch 4/10\n",
      "31884/31884 [==============================] - 40s 1ms/step - loss: 1.3368\n",
      "Epoch 5/10\n",
      "31884/31884 [==============================] - 42s 1ms/step - loss: 1.2777\n",
      "Epoch 6/10\n",
      "31884/31884 [==============================] - 42s 1ms/step - loss: 1.2271\n",
      "Epoch 7/10\n",
      "31884/31884 [==============================] - 41s 1ms/step - loss: 1.1748\n",
      "Epoch 8/10\n",
      "31884/31884 [==============================] - 40s 1ms/step - loss: 1.1278\n",
      "Epoch 9/10\n",
      "31884/31884 [==============================] - 40s 1ms/step - loss: 1.0858\n",
      "Epoch 10/10\n",
      "31884/31884 [==============================] - 54s 2ms/step - loss: 1.0388\n",
      "\n",
      "Iteration 2\n",
      "ll the with see,\n",
      "delights do i and and sor my love's for lis,\n",
      "and live in minds soov thy fair where the with mine, thou art before thee is my brien,\n",
      "thy love in live the lis love in live it sun sight.\n",
      "\n",
      "xxv\n",
      "\n",
      "if that weil see the living ar far eyes \n",
      "i lat of my love's beauty shall from thee\n",
      "the breat shall for a soment of the with,\n",
      "if the world in my love to have that weat sich arl,\n",
      "ar farret,\n",
      "and a\n",
      "\n",
      "Epoch 1/10\n",
      "31884/31884 [==============================] - 48s 2ms/step - loss: 1.0030\n",
      "Epoch 2/10\n",
      "31884/31884 [==============================] - 48s 2ms/step - loss: 0.9676\n",
      "Epoch 3/10\n",
      "31884/31884 [==============================] - 42s 1ms/step - loss: 0.9377\n",
      "Epoch 4/10\n",
      "31884/31884 [==============================] - 41s 1ms/step - loss: 0.9034\n",
      "Epoch 5/10\n",
      "31884/31884 [==============================] - 45s 1ms/step - loss: 0.8791\n",
      "Epoch 6/10\n",
      "31884/31884 [==============================] - 42s 1ms/step - loss: 0.8437\n",
      "Epoch 7/10\n",
      "31884/31884 [==============================] - 46s 1ms/step - loss: 0.8269\n",
      "Epoch 8/10\n",
      "31884/31884 [==============================] - 53s 2ms/step - loss: 0.8045\n",
      "Epoch 9/10\n",
      "31884/31884 [==============================] - 47s 1ms/step - loss: 0.7825: 2s -\n",
      "Epoch 10/10\n",
      "31884/31884 [==============================] - 51s 2ms/step - loss: 0.7698\n",
      "\n",
      "Iteration 3\n",
      "ive, and he in the gion,\n",
      "  to thy sich thy every the time words hill grow,\n",
      "for thee why to kind on mines your from show,\n",
      "so sing, thou art to and wave sweet heart,\n",
      "and his calite.\n",
      "what i am not so thing out this light,\n",
      "when in the living they my glact of love,\n",
      "on mine own pereart not blight,\n",
      "that in the world i can he that fair,\n",
      "core i live my notel, do a better that i wan,\n",
      "nor my shall in the con\n",
      "\n",
      "Epoch 1/10\n",
      "31884/31884 [==============================] - 45s 1ms/step - loss: 0.7331\n",
      "Epoch 2/10\n",
      "31884/31884 [==============================] - 49s 2ms/step - loss: 0.7147\n",
      "Epoch 3/10\n",
      "31884/31884 [==============================] - 51s 2ms/step - loss: 0.7162\n",
      "Epoch 4/10\n",
      "31884/31884 [==============================] - 42s 1ms/step - loss: 0.6891\n",
      "Epoch 5/10\n",
      "31884/31884 [==============================] - 40s 1ms/step - loss: 0.6607\n",
      "Epoch 6/10\n",
      "31884/31884 [==============================] - 39s 1ms/step - loss: 0.6708\n",
      "Epoch 7/10\n",
      "31884/31884 [==============================] - 39s 1ms/step - loss: 0.6337\n",
      "Epoch 8/10\n",
      "31884/31884 [==============================] - 39s 1ms/step - loss: 0.6224\n",
      "Epoch 9/10\n",
      "31884/31884 [==============================] - 39s 1ms/step - loss: 0.6230\n",
      "Epoch 10/10\n",
      "31884/31884 [==============================] - 39s 1ms/step - loss: 0.6125\n",
      "\n",
      "Iteration 4\n",
      "ck, in pose honour in then dear,\n",
      "that he post which is not to the may dears'd dear,\n",
      "i ar thou art which what i have steenght deed,\n",
      "and thou art thou payst ronger, where in their stowe,\n",
      "on andiless with with his very lait,\n",
      "and a surter evernots be not it with heart,\n",
      "which in thy beauty is i have steen the promsing thy eich,\n",
      "and menir how, 'tile the storme the derine,\n",
      "and a thence shorl in the const\n",
      "\n",
      "Epoch 1/10\n",
      "31884/31884 [==============================] - 39s 1ms/step - loss: 0.6012\n",
      "Epoch 2/10\n",
      "31884/31884 [==============================] - 39s 1ms/step - loss: 0.5903\n",
      "Epoch 3/10\n",
      "31884/31884 [==============================] - 39s 1ms/step - loss: 0.6338\n",
      "Epoch 4/10\n",
      "31884/31884 [==============================] - 39s 1ms/step - loss: 0.5665\n",
      "Epoch 5/10\n",
      "31884/31884 [==============================] - 42s 1ms/step - loss: 0.5503\n",
      "Epoch 6/10\n",
      "31884/31884 [==============================] - 41s 1ms/step - loss: 0.5464\n",
      "Epoch 7/10\n",
      "31884/31884 [==============================] - 43s 1ms/step - loss: 0.5358\n",
      "Epoch 8/10\n",
      "31884/31884 [==============================] - 42s 1ms/step - loss: 0.5284\n",
      "Epoch 9/10\n",
      "31884/31884 [==============================] - 42s 1ms/step - loss: 0.5413\n",
      "Epoch 10/10\n",
      "31884/31884 [==============================] - 43s 1ms/step - loss: 0.5088\n",
      "\n",
      "Iteration 5\n",
      "this live our dear dear,\n",
      "that in thy steet he gave--fie, nor do shall to heart.\n",
      "\n",
      "cxlii\n",
      "\n",
      "as the suce am forsick in my lose so stear,\n",
      "thy beauty coutlass'd the love, with mine, thou be dise, all,\n",
      "that in mine own perest beauty not so drays\n",
      "as every out outwerthoun outmys sue shall sorrid accupape thought,\n",
      "and say that thou thought of such sweet,\n",
      "thou art to che that fair when stoucc whall not so my \n",
      "\n",
      "Epoch 1/10\n",
      "31884/31884 [==============================] - 43s 1ms/step - loss: 0.5287\n",
      "Epoch 2/10\n",
      "31884/31884 [==============================] - 42s 1ms/step - loss: 0.5225\n",
      "Epoch 3/10\n",
      "31884/31884 [==============================] - 41s 1ms/step - loss: 0.4823\n",
      "Epoch 4/10\n",
      "31884/31884 [==============================] - 42s 1ms/step - loss: 0.4922\n",
      "Epoch 5/10\n",
      "31884/31884 [==============================] - 42s 1ms/step - loss: 0.4875\n",
      "Epoch 6/10\n",
      "31884/31884 [==============================] - 38s 1ms/step - loss: 0.5048\n",
      "Epoch 7/10\n",
      "31884/31884 [==============================] - 42s 1ms/step - loss: 0.4801\n",
      "Epoch 8/10\n",
      "31884/31884 [==============================] - 42s 1ms/step - loss: 0.4924\n",
      "Epoch 9/10\n",
      "31884/31884 [==============================] - 42s 1ms/step - loss: 0.4623\n",
      "Epoch 10/10\n",
      "31884/31884 [==============================] - 40s 1ms/step - loss: 0.4629\n",
      "\n",
      "Iteration 6\n",
      "or the ridem's cruek in my heart i amoundenst\n",
      "iring and in thee,\n",
      "when to make my single words, though me love, my might,\n",
      "when i she that my sightly omes thy priviig\n",
      "that burnse thy should be thou'd shall show,\n",
      "spends of an urrow my both spends sich your proos'd,\n",
      "being framte my lose eyes bart, should bright\n",
      "dombst my sporion wamphed. no praise wan,\n",
      "if but by this soov'd with more the world'd,\n",
      "and \n",
      "\n",
      "Epoch 1/10\n",
      "31884/31884 [==============================] - 36s 1ms/step - loss: 0.4619\n",
      "Epoch 2/10\n",
      "31884/31884 [==============================] - 37s 1ms/step - loss: 0.4700\n",
      "Epoch 3/10\n",
      "31884/31884 [==============================] - 37s 1ms/step - loss: 0.4766\n",
      "Epoch 4/10\n",
      "31884/31884 [==============================] - 37s 1ms/step - loss: 0.4306\n",
      "Epoch 5/10\n",
      "31884/31884 [==============================] - 36s 1ms/step - loss: 0.4172\n",
      "Epoch 6/10\n",
      "31884/31884 [==============================] - 37s 1ms/step - loss: 0.4393\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31884/31884 [==============================] - 37s 1ms/step - loss: 0.4630\n",
      "Epoch 8/10\n",
      "31884/31884 [==============================] - 42s 1ms/step - loss: 0.4257\n",
      "Epoch 9/10\n",
      "31884/31884 [==============================] - 49s 2ms/step - loss: 0.4156\n",
      "Epoch 10/10\n",
      "31884/31884 [==============================] - 50s 2ms/step - loss: 0.4105: 2s\n",
      "\n",
      "Iteration 7\n",
      "eaph and love, where in their race,\n",
      "and caplangion queppeainded, not so to see,\n",
      "like the sweet her thou dost bide i wan wrich ho reathes\n",
      "asted bestidaity how my sees in my rend\n",
      "fart thy heart, and this wills the world'd,\n",
      "and they all me at fllater belies thou ures\n",
      " for that gendsus' eccoprare when thou my selfen'?\n",
      "whise have you mand, make he waskin gond,\n",
      "which thou dost bern is be steno summer gr\n",
      "\n",
      "Epoch 1/10\n",
      "31884/31884 [==============================] - 46s 1ms/step - loss: 0.4442\n",
      "Epoch 2/10\n",
      "31884/31884 [==============================] - 46s 1ms/step - loss: 0.4232\n",
      "Epoch 3/10\n",
      "31884/31884 [==============================] - 49s 2ms/step - loss: 0.3998\n",
      "Epoch 4/10\n",
      "31884/31884 [==============================] - 49s 2ms/step - loss: 0.3805\n",
      "Epoch 5/10\n",
      "31884/31884 [==============================] - 49s 2ms/step - loss: 0.4068\n",
      "Epoch 6/10\n",
      "31884/31884 [==============================] - 49s 2ms/step - loss: 0.3844\n",
      "Epoch 7/10\n",
      "31884/31884 [==============================] - 49s 2ms/step - loss: 0.4020\n",
      "Epoch 8/10\n",
      "31884/31884 [==============================] - 49s 2ms/step - loss: 0.3580\n",
      "Epoch 9/10\n",
      "31884/31884 [==============================] - 46s 1ms/step - loss: 0.4424\n",
      "Epoch 10/10\n",
      "31884/31884 [==============================] - 48s 2ms/step - loss: 0.3766\n",
      "\n",
      "Iteration 8\n",
      "rnfinst,.\n",
      "and they deemsepping'st thou thy sweet in dee:\n",
      "there in their fade thou shouldse om sun.\n",
      "\n",
      "xlii\n",
      "\n",
      "thou art timen that 'date as thou art my forso,\n",
      "and love i majell doth preserfed;\n",
      "for thy deadow hap year ofte that sinst gher,\n",
      "who hat fors that my swaite thou thy shom.\n",
      "\n",
      "lv\n",
      "\n",
      "ghen tere woll best of their recterest berner ded:\n",
      "thy pows for right did sick womble swall,\n",
      "that in their swaet i lov\n",
      "\n",
      "Epoch 1/10\n",
      "31884/31884 [==============================] - 51s 2ms/step - loss: 0.3579\n",
      "Epoch 2/10\n",
      "31884/31884 [==============================] - 40s 1ms/step - loss: 0.4200\n",
      "Epoch 3/10\n",
      "31884/31884 [==============================] - 38s 1ms/step - loss: 0.3807\n",
      "Epoch 4/10\n",
      "31884/31884 [==============================] - 38s 1ms/step - loss: 0.3694\n",
      "Epoch 5/10\n",
      "31884/31884 [==============================] - 38s 1ms/step - loss: 0.3812\n",
      "Epoch 6/10\n",
      "31884/31884 [==============================] - 40s 1ms/step - loss: 0.3614\n",
      "Epoch 7/10\n",
      "31884/31884 [==============================] - 40s 1ms/step - loss: 0.3449\n",
      "Epoch 8/10\n",
      "31884/31884 [==============================] - 40s 1ms/step - loss: 0.3895\n",
      "Epoch 9/10\n",
      "31884/31884 [==============================] - 40s 1ms/step - loss: 0.4206\n",
      "Epoch 10/10\n",
      "31884/31884 [==============================] - 41s 1ms/step - loss: 0.3748\n",
      "\n",
      "Iteration 9\n",
      "onl's it my some crust i may i am not,\n",
      "and bring a domand romes to eatter to cragle?\n",
      "on les liver one own the would the fade\n",
      "what stouldne i seen tine himpy: bight,\n",
      "and keinting the wolld, and reservety;\n",
      "for i love theress by paysings thres with eres,\n",
      "on presing that blessirss that steen time;\n",
      "my speak there of thy suce that in the grovs\n",
      "\n",
      "hour in the farter thing all my beaut.\n",
      "\n",
      "cxxii\n",
      "\n",
      "and a thou a\n",
      "\n",
      "Epoch 1/10\n",
      "31884/31884 [==============================] - 41s 1ms/step - loss: 0.3481\n",
      "Epoch 2/10\n",
      "31884/31884 [==============================] - 41s 1ms/step - loss: 0.3469\n",
      "Epoch 3/10\n",
      "31884/31884 [==============================] - 40s 1ms/step - loss: 0.3413\n",
      "Epoch 4/10\n",
      "31884/31884 [==============================] - 39s 1ms/step - loss: 0.3403\n",
      "Epoch 5/10\n",
      "31884/31884 [==============================] - 39s 1ms/step - loss: 0.3533\n",
      "Epoch 6/10\n",
      "31884/31884 [==============================] - 39s 1ms/step - loss: 0.3579\n",
      "Epoch 7/10\n",
      "31884/31884 [==============================] - 38s 1ms/step - loss: 0.3450\n",
      "Epoch 8/10\n",
      "31884/31884 [==============================] - 39s 1ms/step - loss: 0.3425\n",
      "Epoch 9/10\n",
      "31884/31884 [==============================] - 39s 1ms/step - loss: 0.3617\n",
      "Epoch 10/10\n",
      "31884/31884 [==============================] - 40s 1ms/step - loss: 0.3267\n",
      "\n",
      "Iteration 10\n",
      " a'd will doth pleas, thou my reile,\n",
      "which be is my lony-liver of a perfest;\n",
      "but thou art by unkind heaven true lons,\n",
      "mating encelf, but thy fower, which betwer since,\n",
      "and when yourinst levers am dear ridid,\n",
      "ar thy heart right did receeves thy fad:\n",
      "  as those living ar my mine own desert,\n",
      "in of my bast ard you agd forle--forte;\n",
      "but not kind and happy are fore form;\n",
      "for like pleasure of thy succend\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for iteration in range(1, 11):\n",
    "    model.fit(x, y,\n",
    "              batch_size=128,\n",
    "              epochs=10)\n",
    "    \n",
    "# generating text\n",
    "    print('\\nIteration', iteration)\n",
    "    start_index = np.random.randint(0, len(text) - maxlen - 1)\n",
    "    sentence = text[start_index: start_index + maxlen]\n",
    "\n",
    "\n",
    "    for i in range(400):\n",
    "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "        for t, char in enumerate(sentence):\n",
    "            x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "        preds = model.predict(x_pred, verbose=0)[0]      #predict using model, generating a matrix of softmax\n",
    "        next_index = np.argmax(preds)                    #we want the index with highest probability \n",
    "        next_char = indices_char[next_index]             #convert number back to character using the dictionary\n",
    "        sentence = sentence[1:] + next_char              #append the character predicted to the sentence (start from the second character)\n",
    "\n",
    "        sys.stdout.write(next_char)                \n",
    "        sys.stdout.flush()\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

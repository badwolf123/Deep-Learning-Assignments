{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function            \n",
    "import keras \n",
    "from keras.models import Sequential                \n",
    "from keras.layers import Dense, Activation         \n",
    "                                                  \n",
    "from keras.optimizers import Adam                   \n",
    "\n",
    "import pandas                                       \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pandas.read_csv(\"train.csv\") \n",
    "dataset = dataset.as_matrix() \n",
    "X,y = dataset[:,1:], dataset[:,0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of features is: (42000, 784)\n",
      "the shape of labels is: (42000,)\n",
      "the range of features is: 0 to 255\n",
      "the range of labels is: 0 to 9\n",
      "label 1 is 1\n",
      "label 2 is 0\n",
      "label 3 is 1\n",
      "label 4 is 4\n",
      "label 5 is 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1844e8e6208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print ('the shape of features is:',X.shape)       \n",
    "print ('the shape of labels is:',y.shape)       \n",
    "\n",
    "import numpy as np\n",
    "print ('the range of features is:',np.min(X),'to',np.max(X))\n",
    "print ('the range of labels is:',np.min(y),'to',np.max(y))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline\n",
    "for i in range(5):\n",
    "    image = X[i]\n",
    "    plt.subplot(1,10, i+1)\n",
    "    image = image.reshape(28,28)\n",
    "    print ('label', i+1, 'is',y[i])\n",
    "    plt.imshow(image, cmap='Greys')\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.20) \n",
    "\n",
    "x_train = x_train/255.0                           \n",
    "x_val = x_val/255.0                             \n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 备注\n",
    "这里我加了一个hidden layer并尝试过改变neurons，batch_size和learning_rate的参数值，最终使用的参数如下所示，同时我利用keras documentation找到了可选用的optimizers，都尝试了一下，发现Adam是输出准确率最高的，其输出结果如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 256)               200960    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 251,658\n",
      "Trainable params: 251,658\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# set parameters\n",
    "batch_size = 128\n",
    "epochs = 300\n",
    "learning_rate = 0.001\n",
    "\n",
    "# build the model\n",
    "model = Sequential()                                         \n",
    "model.add(Dense(256, activation='relu',input_dim=784))       \n",
    "model.add(Dense(128, activation='relu'))                     \n",
    "model.add(Dense(128, activation='relu'))                     # third hidden layer with 128 neurons\n",
    "model.add(Dense(10, activation='softmax'))                   \n",
    "model.summary()                                              \n",
    "\n",
    "\n",
    "my_optimizer = keras.optimizers.Adam(lr=learning_rate)    \n",
    "model.compile(optimizer=my_optimizer,                        # using Adam with our set lr as optimizer\n",
    "              loss='categorical_crossentropy',               \n",
    "              metrics=['accuracy'])                          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 33600 samples, validate on 8400 samples\n",
      "Epoch 1/300\n",
      " - 3s - loss: 0.3573 - acc: 0.8967 - val_loss: 0.1730 - val_acc: 0.9500\n",
      "Epoch 2/300\n",
      " - 2s - loss: 0.1271 - acc: 0.9617 - val_loss: 0.1147 - val_acc: 0.9638\n",
      "Epoch 3/300\n",
      " - 2s - loss: 0.0840 - acc: 0.9740 - val_loss: 0.1292 - val_acc: 0.9619\n",
      "Epoch 4/300\n",
      " - 2s - loss: 0.0601 - acc: 0.9812 - val_loss: 0.1103 - val_acc: 0.9679\n",
      "Epoch 5/300\n",
      " - 2s - loss: 0.0413 - acc: 0.9875 - val_loss: 0.0961 - val_acc: 0.9733\n",
      "Epoch 6/300\n",
      " - 2s - loss: 0.0311 - acc: 0.9902 - val_loss: 0.1112 - val_acc: 0.9706\n",
      "Epoch 7/300\n",
      " - 2s - loss: 0.0253 - acc: 0.9921 - val_loss: 0.0918 - val_acc: 0.9756\n",
      "Epoch 8/300\n",
      " - 2s - loss: 0.0164 - acc: 0.9950 - val_loss: 0.1048 - val_acc: 0.9746\n",
      "Epoch 9/300\n",
      " - 2s - loss: 0.0154 - acc: 0.9951 - val_loss: 0.1086 - val_acc: 0.9735\n",
      "Epoch 10/300\n",
      " - 2s - loss: 0.0157 - acc: 0.9945 - val_loss: 0.1301 - val_acc: 0.9695\n",
      "Epoch 11/300\n",
      " - 2s - loss: 0.0191 - acc: 0.9934 - val_loss: 0.1082 - val_acc: 0.9727\n",
      "Epoch 12/300\n",
      " - 2s - loss: 0.0112 - acc: 0.9966 - val_loss: 0.1272 - val_acc: 0.9724\n"
     ]
    }
   ],
   "source": [
    "best_weights_filepath = './best_weights.hdf5' ##define the filename to store\n",
    "                                            ##the best performance and weights\n",
    "earlyStopping = keras.callbacks.EarlyStopping(monitor='val_acc',\n",
    "                                              patience = 5) \n",
    "#Stop training early if val_acc doesn't improve for 5 epochs\n",
    "\n",
    "SaveBestWeights = keras.callbacks.ModelCheckpoint(best_weights_filepath,\n",
    "                                                  monitor='val_acc',\n",
    "                                                  save_best_only=True)\n",
    "# store the historically best performing weights in best_weights_filepath\n",
    "#, where performance is given by accuracy on the validation set.\n",
    "\n",
    "\n",
    "model_history = model.fit(x_train, y_train,                   # training data \n",
    "                    batch_size=batch_size,                   # batch size 256\n",
    "                    epochs=epochs,                           # 300 epochs \n",
    "                    verbose= 2,                              # verbose level\n",
    "                    validation_data = (x_val, y_val),  #Use the previously defined x_test as a validation set. \n",
    "                    callbacks = [earlyStopping, SaveBestWeights]\n",
    "                         )     \n",
    "model.load_weights(best_weights_filepath) ##Set the best performing weights to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = pandas.read_csv(\"test.csv\")             # Read data\n",
    "testset = testset.as_matrix()                     # Convert to ndarray\n",
    "testset = testset/255.0                             # normalize testing data\n",
    "predictions = model.predict_classes(testset)           # Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pandas.DataFrame(data=predictions, index=np.arange(1,len(predictions)+1), columns=['Label']) # Create dataframe\n",
    "submission.index.name = 'ImageId' # Set index name\n",
    "\n",
    "csv_text = submission.to_csv() # Convert to text\n",
    "\n",
    "# Write to file 'submission.csv'\n",
    "with open(\"submission.csv\",'w') as csv_file:\n",
    "    csv_file.write(csv_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
